# ==============================================================================\n# analysis.py -- Analysis and Visualization Functions\n# ==============================================================================\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, pairwise\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm\nimport jax\nimport jax.numpy as jnp\nfrom functools import partial\nfrom flax import nnx\n\ndef plot_training_curves(history, model_name):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    fig.suptitle(f'Fine-Tuning Curves for {model_name}', fontsize=16, fontweight='bold')\n    steps = range(len(history['train_loss']))\n    ax1.plot(steps, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n    ax1.plot(steps, history['test_loss'], 'r--', label='Test Loss', linewidth=2)\n    ax1.set_title('Loss')\n    ax1.set_xlabel('Evaluation Steps')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    ax2.plot(steps, history['train_accuracy'], 'b-', label='Train Accuracy', linewidth=2)\n    ax2.plot(steps, history['test_accuracy'], 'r--', label='Test Accuracy', linewidth=2)\n    ax2.set_title('Accuracy')\n    ax2.set_xlabel('Evaluation Steps')\n    ax2.set_ylabel('Accuracy')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\ndef print_final_metrics(history, model_name):\n    print(f"\n\U0001F4CA FINAL METRICS FOR {model_name}" + "\n" + "=" * 40)\n    final_metrics = {metric: hist[-1] for metric, hist in history.items() if hist}\n    if not final_metrics:\n        print("No metrics recorded.")\n        return\n    print(f"{'Metric':<20} {'Value':<15}")\n    print("-" * 35)\n    for metric, value in final_metrics.items():\n        print(f"{metric:<20} {value:<15.4f}")\n    print("\n\U0001F3C6 SUMMARY:")\n    print(f"    Final Test Accuracy: {final_metrics.get('test_accuracy', 0):.4f}")\n\ndef detailed_test_evaluation(model, test_ds_iter, class_names: list[str], model_name: str):\n    print(f"\n\U0001F52C Running detailed test evaluation for {model_name}...")\n    num_classes = len(class_names)\n    predictions, true_labels = [], []\n    for batch in tqdm(test_ds_iter, desc="Detailed Evaluation"):\n        preds = jnp.argmax(model(batch['image'], training=False), axis=1)\n        predictions.extend(preds.tolist())\n        true_labels.extend(batch['label'].tolist())\n    predictions, true_labels = np.array(predictions), np.array(true_labels)\n    print("\n\U0001F3AF PER-CLASS ACCURACY" + "\n" + "=" * 50)\n    print(f"{'Class':<15} {'Accuracy':<10} {'Sample Count':<12}")\n    print("-" * 50)\n    for i in range(num_classes):\n        mask = true_labels == i\n        if np.sum(mask) > 0:\n            acc = np.mean(predictions[mask] == true_labels[mask])\n            print(f"{class_names[i]:<15} {acc:<10.4f} {np.sum(mask):<12}")\n    return {'predictions': predictions, 'true_labels': true_labels, 'class_names': class_names}\n\ndef plot_confusion_matrix(predictions_data, model_name):\n    cm = confusion_matrix(predictions_data['true_labels'], predictions_data['predictions'])\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predictions_data['class_names'], yticklabels=predictions_data['class_names'])\n    plt.title(f'{model_name} - Confusion Matrix', fontweight='bold')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.tight_layout()\n    plt.show()\n\ndef visualize_tsne(encoder, dataset_iter, class_names: list[str], title: str, num_samples: int = 1000):\n    print(f"\n\U0001F3A8 Generating t-SNE plot: {title}...")\n    all_embeddings = []\n    all_labels = []\n    batch_size = 32\n    total_iters = int(np.ceil(num_samples / batch_size))\n    for batch in tqdm(dataset_iter, desc="Extracting embeddings for t-SNE", total=total_iters):\n        embeddings = encoder(batch['image'], training=False, return_activations_for_layer='representation')\n        all_embeddings.append(np.array(embeddings))\n        all_labels.append(np.array(batch['label']))\n        if len(np.concatenate(all_labels)) >= num_samples:\n            break\n    all_embeddings = np.concatenate(all_embeddings, axis=0)[:num_samples]\n    all_labels = np.concatenate(all_labels, axis=0)[:num_samples]\n    if all_embeddings.shape[0] < 2:\n        print("Not enough samples for t-SNE plot.")\n        return\n    output_neurons = np.array(encoder.out_linear.kernel.value).T\n    num_neurons = output_neurons.shape[0]\n    combined_data = np.vstack((all_embeddings, output_neurons))\n    scaler = StandardScaler()\n    combined_data_scaled = scaler.fit_transform(combined_data)\n    perplexity = min(30, combined_data_scaled.shape[0] - 1)\n    tsne = TSNE(n_components=2, verbose=0, perplexity=perplexity, n_iter=300, random_state=42)\n    combined_tsne_results = tsne.fit_transform(combined_data_scaled)\n    image_tsne_results = combined_tsne_results[:-num_neurons]\n    neuron_tsne_results = combined_tsne_results[-num_neurons:]\n    plt.figure(figsize=(14, 12))\n    cmap = plt.cm.get_cmap("jet", len(class_names))\n    scatter = plt.scatter(image_tsne_results[:,0], image_tsne_results[:,1], c=all_labels, cmap=cmap, alpha=0.6)\n    plt.scatter(neuron_tsne_results[:, 0], neuron_tsne_results[:, 1], marker='*', c=range(len(class_names)), cmap=cmap, s=800, edgecolor='black', linewidth=1.5)\n    plt.title(title, fontsize=16, fontweight='bold')\n    plt.xlabel("t-SNE Dimension 1")\n    plt.ylabel("t-SNE Dimension 2")\n    handles, _ = scatter.legend_elements(prop="colors", alpha=0.6)\n    neuron_handle = plt.Line2D([0], [0], marker='*', color='w', label='Class Neuron', markerfacecolor='grey', markeredgecolor='k', markersize=20)\n    plt.legend(handles=handles + [neuron_handle], labels=class_names + ['Class Neuron'], title="Classes")\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\ndef visualize_reconstructions(autoencoder, dataset_iter, title: str, num_images: int = 8):\n    print(f"\n\U0001F5BC\uFE0F  Generating image reconstructions: {title}...")\n    try:\n        batch = next(dataset_iter)\n    except StopIteration:\n        print("Could not get a batch to visualize reconstructions.")\n        return\n    original_images = batch['original_image'][:num_images]\n    augmented_images = batch['augmented_image'][:num_images]\n    reconstructed_images = autoencoder(augmented_images, training=False)\n    original_images = np.array(original_images)\n    augmented_images = np.array(augmented_images)\n    reconstructed_images = np.array(reconstructed_images)\n    n = min(num_images, len(original_images))\n    plt.figure(figsize=(20, 6))\n    for i in range(n):\n        ax = plt.subplot(3, n, i + 1)\n        plt.imshow(augmented_images[i])\n        plt.title("Augmented Input")\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n        ax = plt.subplot(3, n, i + 1 + n)\n        plt.imshow(reconstructed_images[i])\n        plt.title("Reconstructed")\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n        ax = plt.subplot(3, n, i + 1 + 2 * n)\n        plt.imshow(original_images[i])\n        plt.title("Original Target")\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.suptitle(title, fontsize=16, fontweight='bold')\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\n# --- Saliency Map Generation, Kernel Similarity, Adversarial Attack, and Robustness Analysis functions should also be moved here from main.py.\n# For brevity, only the function signatures and comments are included here. Move the full function bodies from main.py and update imports as needed. 